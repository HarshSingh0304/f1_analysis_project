{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fd421c-ae44-4392-9219-f3201ebfd420",
   "metadata": {},
   "source": [
    "# üìì Notebook 05 ‚Äî Undercut Detection & Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Context: Why This Notebook Exists\n",
    "\n",
    "Notebook 04 marked a decisive transition in this project.\n",
    "\n",
    "At its conclusion, we achieved something rare in sports analytics pipelines:\n",
    "\n",
    "> **A lap-level dataset that is temporally explicit, structurally validated, and free of hidden inference.**\n",
    "\n",
    "All upstream concerns have now been resolved:\n",
    "\n",
    "- Data ingestion is complete\n",
    "- Schema ambiguity has been eliminated\n",
    "- Relational integrity is enforced\n",
    "- Lap grain is immutable\n",
    "- Time is continuous and monotonic\n",
    "- Track status is mechanically aligned\n",
    "- Pit structure and stints are explicitly defined\n",
    "- Silent analytical corruption has been ruled out via invariant enforcement\n",
    "\n",
    "This means we are no longer asking:\n",
    "> *‚ÄúCan we trust the data?‚Äù*\n",
    "\n",
    "We are now in a position to ask:\n",
    "> **‚ÄúWhat does the data actually say?‚Äù**\n",
    "\n",
    "Notebook 05 is where the **core question of this project is finally addressed**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Central Question of the Project\n",
    "\n",
    "The motivating question behind this entire analysis is simple to state, but difficult to answer rigorously:\n",
    "\n",
    "> **Is the undercut a consistently valuable race strategy in modern Formula 1 ‚Äî or is its reputation largely hype?**\n",
    "\n",
    "Answering this requires more than anecdotal examples or selective race replays.\n",
    "\n",
    "It requires:\n",
    "- precise definitions\n",
    "- controlled comparisons\n",
    "- explicit assumptions\n",
    "- repeatable evaluation\n",
    "\n",
    "Notebook 05 is where those requirements are met.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What ‚ÄúUndercut‚Äù Means in This Project\n",
    "\n",
    "Before proceeding, it is crucial to clarify the **analytical framing** of this notebook.\n",
    "\n",
    "This notebook is **not** concerned with:\n",
    "- how teams *intend* to undercut\n",
    "- radio messages or strategy calls\n",
    "- post-race narratives\n",
    "\n",
    "Instead, it focuses on **observable outcomes**:\n",
    "\n",
    "> *Given two drivers on track, when one pits earlier and rejoins, does that decision produce a measurable net advantage once pit-cycle effects are accounted for?*\n",
    "\n",
    "In other words:\n",
    "- Undercut is treated as a **measurable event**\n",
    "- Success or failure is defined **empirically**\n",
    "- Evaluation is done **after the fact**, not inferred from intent\n",
    "\n",
    "This framing is essential to avoid circular reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Why Undercut *Detection* Comes After Notebook 04\n",
    "\n",
    "Notebook 04 deliberately avoided all strategy logic.\n",
    "\n",
    "That was not a limitation ‚Äî it was a prerequisite.\n",
    "\n",
    "Undercut detection **requires**:\n",
    "\n",
    "- Clean lap-to-lap deltas\n",
    "- Accurate pit and out-lap identification\n",
    "- Correct stint segmentation\n",
    "- Reliable gap-to-leader and relative timing\n",
    "- Explicit track-status context\n",
    "- Confidence that ambiguous data has not been silently ‚Äúfixed‚Äù\n",
    "\n",
    "All of these are now guaranteed.\n",
    "\n",
    "As a result, Notebook 05 can operate without:\n",
    "- defensive coding\n",
    "- implicit assumptions\n",
    "- hidden data cleaning steps\n",
    "\n",
    "This notebook assumes Notebook 04‚Äôs guarantees as **axioms**, not hypotheses.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Analytical Scope of Notebook 05\n",
    "\n",
    "Notebook 05 has a **precise and limited scope**, aligned with the pipeline document.\n",
    "\n",
    "It will do **three things**, and only three things:\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Detect Undercut Events üîç\n",
    "\n",
    "This notebook will identify **candidate undercut situations**, defined operationally by:\n",
    "\n",
    "- Relative track position before pit cycles\n",
    "- Early pit stop by one driver relative to a competitor\n",
    "- Overlapping stint transitions\n",
    "- Comparable race context (same race, same lap window)\n",
    "\n",
    "Detection will be:\n",
    "- rule-based\n",
    "- deterministic\n",
    "- reproducible\n",
    "\n",
    "No subjective labeling will be introduced.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Evaluate Undercut Outcomes üìä\n",
    "\n",
    "For each detected undercut event, this notebook will evaluate:\n",
    "\n",
    "- Net time gained or lost after the pit cycle\n",
    "- Position changes attributable to the pit timing\n",
    "- Lap windows over which the outcome materializes\n",
    "\n",
    "Evaluation will:\n",
    "- use only green-flag competitive laps (as explicitly defined here)\n",
    "- exclude pit laps and out laps by construction\n",
    "- control for obvious confounders (e.g., safety cars)\n",
    "\n",
    "This step turns ‚Äúundercut‚Äù from a narrative into a **measured quantity**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Aggregate & Interpret Results üìà\n",
    "\n",
    "Finally, Notebook 05 will aggregate undercut outcomes:\n",
    "\n",
    "- across races\n",
    "- across seasons\n",
    "- across compounds\n",
    "- across stint lengths\n",
    "- across grid positions\n",
    "\n",
    "The goal is **not** to cherry-pick examples, but to observe **distributions and tendencies**.\n",
    "\n",
    "Only at this stage will interpretation begin.\n",
    "\n",
    "---\n",
    "\n",
    "## üö¶ Handling Track Status Ambiguity (Explicitly)\n",
    "\n",
    "Notebook 04 intentionally allowed ambiguity in track status alignment.\n",
    "\n",
    "Notebook 05 resolves that ambiguity **explicitly**, not implicitly.\n",
    "\n",
    "This notebook will:\n",
    "- define what constitutes a *competitive green lap*\n",
    "- exclude laps affected by SC, VSC, or red flags\n",
    "- justify exclusions transparently\n",
    "\n",
    "This is a conscious analytical choice, not a data-cleaning hack.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ What This Notebook Will *Not* Do\n",
    "\n",
    "To maintain analytical discipline, Notebook 05 will **not**:\n",
    "\n",
    "- modify upstream features\n",
    "- redefine lap grain\n",
    "- reclassify pit laps\n",
    "- infer driver intent\n",
    "- speculate on team strategy calls\n",
    "\n",
    "All inputs are treated as fixed.\n",
    "\n",
    "If an assumption is required, it will be:\n",
    "- stated explicitly\n",
    "- tested where possible\n",
    "- discussed in limitations\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Expected Outputs\n",
    "\n",
    "At the end of Notebook 05, we expect to have:\n",
    "\n",
    "- A catalog of detected undercut events\n",
    "- Quantified outcomes for each event\n",
    "- Summary statistics describing undercut effectiveness\n",
    "- Evidence for or against the ‚Äúundercut advantage‚Äù hypothesis\n",
    "\n",
    "Importantly:\n",
    "\n",
    "> **The results may confirm, weaken, or outright contradict common F1 strategy narratives.**\n",
    "\n",
    "This notebook is designed to accept any of those outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why This Notebook Matters\n",
    "\n",
    "Undercut strategy is often discussed as if its effectiveness were self-evident.\n",
    "\n",
    "Notebook 05 treats that belief as a **testable hypothesis**, not a given.\n",
    "\n",
    "Because of the rigor enforced in Notebooks 00‚Äì04:\n",
    "\n",
    "- any conclusion reached here is grounded\n",
    "- any limitation is visible\n",
    "- any disagreement can be traced back to explicit choices\n",
    "\n",
    "This is where the project stops preparing to analyze ‚Äî  \n",
    "and starts **actually analyzing**.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Road Ahead\n",
    "\n",
    "This notebook is the analytical core of the project.\n",
    "\n",
    "Subsequent notebooks, if any, will focus on:\n",
    "- robustness checks\n",
    "- sensitivity analysis\n",
    "- alternative definitions\n",
    "- extensions or counterfactuals\n",
    "\n",
    "But none of that is possible unless **this notebook is done correctly**.\n",
    "\n",
    "With the foundation sealed, we now proceed.\n",
    "\n",
    "> **Notebook 05 begins here.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddc3ad1-dc4c-4589-abe0-ab251421689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:06:42,077 | INFO | src.logging_config | Notebook 05 started ‚Äî Undercut Detection & Evaluation\n",
      "2025-12-18 17:06:42,204 | INFO | src.logging_config | PostgreSQL engine initialized successfully\n",
      "2025-12-18 17:06:42,206 | INFO | src.logging_config | Loading lap-level dataset produced by Notebook 04\n",
      "2025-12-18 17:06:43,216 | INFO | src.logging_config | Lap dataset loaded ‚Äî rows: 74,605, races: 68, drivers: 28\n",
      "2025-12-18 17:06:43,218 | INFO | src.logging_config | All required Notebook 04 output columns are present\n",
      "2025-12-18 17:06:43,247 | INFO | src.logging_config | Lap grain integrity confirmed\n",
      "2025-12-18 17:06:43,250 | INFO | src.logging_config | Temporal integrity confirmed\n",
      "2025-12-18 17:06:43,255 | INFO | src.logging_config | Derived feature expectations confirmed\n",
      "2025-12-18 17:06:43,257 | INFO | src.logging_config | Notebook 05 preconditions satisfied ‚Äî Notebook 04 output accepted as strategy-safe input\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 1\n",
    "# Environment Setup, Data Load & Contract Assertions\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "Notebook 05 ‚Äî Undercut Detection & Evaluation\n",
    "\n",
    "This cell performs ONLY:\n",
    "‚Ä¢ Environment and logging setup\n",
    "‚Ä¢ Loading of Notebook 04 outputs\n",
    "‚Ä¢ Assertion of upstream guarantees\n",
    "\n",
    "This cell MUST NOT:\n",
    "‚Ä¢ perform strategy logic\n",
    "‚Ä¢ redefine features\n",
    "‚Ä¢ modify data\n",
    "‚Ä¢ filter laps\n",
    "‚Ä¢ infer competitiveness\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Standard library imports\n",
    "# -----------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Third-party imports\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Resolve project root robustly\n",
    "# -----------------------------\n",
    "cwd = Path.cwd().resolve()\n",
    "\n",
    "PROJECT_ROOT = None\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / \"src\").exists():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not locate project root (directory containing 'src/')\"\n",
    "    )\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# -----------------------------\n",
    "# Project-level imports\n",
    "# -----------------------------\n",
    "from src.config import Config\n",
    "from src.db import get_engine\n",
    "from src.logging_config import setup_logging\n",
    "\n",
    "# -----------------------------\n",
    "# Logging setup\n",
    "# -----------------------------\n",
    "logger, _ = setup_logging()\n",
    "logger.info(\"Notebook 05 started ‚Äî Undercut Detection & Evaluation\")\n",
    "\n",
    "# -----------------------------\n",
    "# Database connection\n",
    "# -----------------------------\n",
    "engine = get_engine()\n",
    "logger.info(\"PostgreSQL engine initialized successfully\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load lap-level dataset (Notebook 04 output)\n",
    "# -----------------------------\n",
    "logger.info(\"Loading lap-level dataset produced by Notebook 04\")\n",
    "\n",
    "lap_frame = pd.read_sql(\"SELECT * FROM lap_features\", engine)\n",
    "\n",
    "logger.info(\n",
    "    f\"Lap dataset loaded ‚Äî rows: {len(lap_frame):,}, \"\n",
    "    f\"races: {lap_frame['race_id'].nunique()}, \"\n",
    "    f\"drivers: {lap_frame['driver_code'].nunique()}\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî REQUIRED columns\n",
    "# -----------------------------\n",
    "REQUIRED_COLUMNS = [\n",
    "    \"race_id\",\n",
    "    \"driver_code\",\n",
    "    \"lap_number\",\n",
    "    \"lap_start_time_ms\",\n",
    "    \"lap_end_time_ms\",\n",
    "    \"cumulative_time_ms\",\n",
    "    \"gap_to_leader_ms\",\n",
    "    \"delta_prev_lap_ms\",\n",
    "    \"is_green_lap\",\n",
    "    \"is_sc_lap\",\n",
    "    \"is_vsc_lap\",\n",
    "    \"is_red_lap\",\n",
    "    \"is_pit_lap\",\n",
    "    \"is_out_lap\",\n",
    "    \"stint_id\",\n",
    "]\n",
    "\n",
    "missing = set(REQUIRED_COLUMNS) - set(lap_frame.columns)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Notebook 05 cannot proceed ‚Äî missing required columns: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "logger.info(\"All required Notebook 04 output columns are present\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî lap grain\n",
    "# -----------------------------\n",
    "if lap_frame.duplicated(\n",
    "    subset=[\"race_id\", \"driver_code\", \"lap_number\"]\n",
    ").any():\n",
    "    raise RuntimeError(\n",
    "        \"Lap grain violation detected ‚Äî Notebook 04 contract broken\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Lap grain integrity confirmed\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî temporal sanity\n",
    "# -----------------------------\n",
    "if (lap_frame[\"lap_end_time_ms\"] < lap_frame[\"lap_start_time_ms\"]).any():\n",
    "    raise RuntimeError(\n",
    "        \"Temporal inconsistency detected ‚Äî invalid lap time windows\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Temporal integrity confirmed\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî delta expectations\n",
    "# -----------------------------\n",
    "bad_delta = lap_frame.loc[\n",
    "    lap_frame[\"delta_prev_lap_ms\"].isna() &\n",
    "    (lap_frame[\"lap_number\"] != 1)\n",
    "]\n",
    "\n",
    "if not bad_delta.empty:\n",
    "    raise RuntimeError(\n",
    "        \"Unexpected NaNs in delta_prev_lap_ms ‚Äî Notebook 04 guarantees violated\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Derived feature expectations confirmed\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final confirmation\n",
    "# -----------------------------\n",
    "logger.info(\n",
    "    \"Notebook 05 preconditions satisfied ‚Äî \"\n",
    "    \"Notebook 04 output accepted as strategy-safe input\"\n",
    ")\n",
    "\n",
    "# NOTE:\n",
    "# Strategy logic begins in Cell 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1606a73b-8de3-471e-8ebd-2af434ebb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:06:43,282 | INFO | src.logging_config | Detecting undercut candidate events (pairwise, lossless)\n",
      "2025-12-18 17:06:43,308 | INFO | src.logging_config | Attacking pit laps identified ‚Äî rows: 72,090\n",
      "2025-12-18 17:06:43,348 | INFO | src.logging_config | Raw undercut candidate pairs generated ‚Äî rows: 1,740\n",
      "2025-12-18 17:06:43,361 | INFO | src.logging_config | Undercut candidate detection complete ‚Äî pairwise events: 1,740\n",
      "2025-12-18 17:06:43,363 | INFO | src.logging_config | Undercut candidate table validated ‚Äî ready for evaluation stage\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 2\n",
    "# Undercut Candidate Detection (Option A, Revised)\n",
    "# ============================================================\n",
    "\n",
    "logger.info(\"Detecting undercut candidate events (pairwise, lossless)\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Identify attacking pit laps\n",
    "# ------------------------------------------------------------\n",
    "attackers = lap_frame.loc[\n",
    "    lap_frame[\"is_pit_lap\"]\n",
    "].copy()\n",
    "\n",
    "attackers = attackers.rename(\n",
    "    columns={\n",
    "        \"driver_code\": \"attacking_driver\",\n",
    "        \"lap_number\": \"pit_lap\",\n",
    "        \"stint_id\": \"pre_pit_stint_id\",\n",
    "        \"cumulative_time_ms\": \"attacker_pit_time_ms\"\n",
    "    }\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Attacking pit laps identified ‚Äî rows: {len(attackers):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Identify defending drivers on the same lap\n",
    "# ------------------------------------------------------------\n",
    "# Defender must be:\n",
    "# ‚Ä¢ in same race\n",
    "# ‚Ä¢ on same lap\n",
    "# ‚Ä¢ not pitting on that lap\n",
    "# ‚Ä¢ not on an out lap\n",
    "\n",
    "defenders = lap_frame.loc[\n",
    "    (~lap_frame[\"is_pit_lap\"]) &\n",
    "    (~lap_frame[\"is_out_lap\"])\n",
    "].copy()\n",
    "\n",
    "defenders = defenders.rename(\n",
    "    columns={\n",
    "        \"driver_code\": \"defending_driver\",\n",
    "        \"stint_id\": \"defender_stint_id\",\n",
    "        \"cumulative_time_ms\": \"defender_time_ms\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Pairwise join: attacker √ó defender\n",
    "# ------------------------------------------------------------\n",
    "undercut_candidates = attackers.merge(\n",
    "    defenders,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"race_id\", \"pit_lap\"],\n",
    "    right_on=[\"race_id\", \"lap_number\"]\n",
    ")\n",
    "\n",
    "# Remove self-pairings\n",
    "undercut_candidates = undercut_candidates.loc[\n",
    "    undercut_candidates[\"attacking_driver\"] !=\n",
    "    undercut_candidates[\"defending_driver\"]\n",
    "]\n",
    "\n",
    "logger.info(\n",
    "    f\"Raw undercut candidate pairs generated ‚Äî rows: {len(undercut_candidates):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Structural cleanup\n",
    "# ------------------------------------------------------------\n",
    "undercut_candidates = undercut_candidates[\n",
    "    [\n",
    "        \"race_id\",\n",
    "        \"pit_lap\",\n",
    "        \"attacking_driver\",\n",
    "        \"defending_driver\",\n",
    "        \"pre_pit_stint_id\",\n",
    "        \"defender_stint_id\",\n",
    "        \"attacker_pit_time_ms\",\n",
    "        \"defender_time_ms\",\n",
    "    ]\n",
    "].sort_values(\n",
    "    by=[\"race_id\", \"pit_lap\", \"attacking_driver\", \"defending_driver\"],\n",
    "    kind=\"mergesort\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "logger.info(\n",
    "    \"Undercut candidate detection complete ‚Äî \"\n",
    "    f\"pairwise events: {len(undercut_candidates):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Sanity check (now meaningful)\n",
    "# ------------------------------------------------------------\n",
    "if undercut_candidates.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No undercut candidates detected ‚Äî unexpected after relaxing track status\"\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    \"Undercut candidate table validated ‚Äî ready for evaluation stage\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519c85d9-7ed9-48cf-a79b-1507dd58a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:06:43,392 | INFO | src.logging_config | Constructing undercut evaluation windows (data-available semantics)\n",
      "2025-12-18 17:08:24,001 | INFO | src.logging_config | Evaluation windows constructed ‚Äî rows: 122, unique candidates: 122\n",
      "2025-12-18 17:08:24,004 | INFO | src.logging_config | Evaluation windows ready for outcome aggregation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 3 (REVISED)\n",
    "# Undercut Evaluation Window Construction\n",
    "# ============================================================\n",
    "\n",
    "logger.info(\"Constructing undercut evaluation windows (data-available semantics)\")\n",
    "\n",
    "EVAL_LAPS = 3\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: laps eligible for mechanical comparison\n",
    "# ------------------------------------------------------------\n",
    "def eligible_eval_laps(df):\n",
    "    \"\"\"\n",
    "    Mechanical eligibility for comparison:\n",
    "    ‚Ä¢ not pit laps\n",
    "    ‚Ä¢ not out laps\n",
    "    Track status is NOT enforced here.\n",
    "    \"\"\"\n",
    "    return df.loc[\n",
    "        (~df[\"is_pit_lap\"]) &\n",
    "        (~df[\"is_out_lap\"])\n",
    "    ]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Prepare lap frame\n",
    "# ------------------------------------------------------------\n",
    "laps_eval = lap_frame.sort_values(\n",
    "    by=[\"race_id\", \"driver_code\", \"lap_number\"],\n",
    "    kind=\"mergesort\"\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Expand each undercut candidate\n",
    "# ------------------------------------------------------------\n",
    "for _, row in undercut_candidates.iterrows():\n",
    "    race_id = row[\"race_id\"]\n",
    "    pit_lap = row[\"pit_lap\"]\n",
    "    attacker = row[\"attacking_driver\"]\n",
    "    defender = row[\"defending_driver\"]\n",
    "\n",
    "    lap_window = range(pit_lap + 1, pit_lap + 1 + EVAL_LAPS)\n",
    "\n",
    "    attacker_laps = laps_eval.loc[\n",
    "        (laps_eval[\"race_id\"] == race_id) &\n",
    "        (laps_eval[\"driver_code\"] == attacker) &\n",
    "        (laps_eval[\"lap_number\"].isin(lap_window))\n",
    "    ]\n",
    "\n",
    "    defender_laps = laps_eval.loc[\n",
    "        (laps_eval[\"race_id\"] == race_id) &\n",
    "        (laps_eval[\"driver_code\"] == defender) &\n",
    "        (laps_eval[\"lap_number\"].isin(lap_window))\n",
    "    ]\n",
    "\n",
    "    attacker_laps = eligible_eval_laps(attacker_laps)\n",
    "    defender_laps = eligible_eval_laps(defender_laps)\n",
    "\n",
    "    merged = attacker_laps.merge(\n",
    "        defender_laps,\n",
    "        how=\"inner\",\n",
    "        on=[\"race_id\", \"lap_number\"],\n",
    "        suffixes=(\"_attacker\", \"_defender\")\n",
    "    )\n",
    "\n",
    "    if merged.empty:\n",
    "        continue\n",
    "\n",
    "    merged[\"pit_lap\"] = pit_lap\n",
    "    merged[\"attacking_driver\"] = attacker\n",
    "    merged[\"defending_driver\"] = defender\n",
    "\n",
    "    records.append(\n",
    "        merged[\n",
    "            [\n",
    "                \"race_id\",\n",
    "                \"pit_lap\",\n",
    "                \"lap_number\",\n",
    "                \"attacking_driver\",\n",
    "                \"defending_driver\",\n",
    "                \"cumulative_time_ms_attacker\",\n",
    "                \"cumulative_time_ms_defender\",\n",
    "                \"is_green_lap_attacker\",\n",
    "                \"is_green_lap_defender\",\n",
    "                \"is_sc_lap_attacker\",\n",
    "                \"is_sc_lap_defender\",\n",
    "                \"is_vsc_lap_attacker\",\n",
    "                \"is_vsc_lap_defender\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Assemble evaluation windows\n",
    "# ------------------------------------------------------------\n",
    "if not records:\n",
    "    raise RuntimeError(\n",
    "        \"No evaluation windows constructed even after relaxing track status ‚Äî \"\n",
    "        \"check pit/out-lap logic\"\n",
    "    )\n",
    "\n",
    "eval_windows = (\n",
    "    pd.concat(records, ignore_index=True)\n",
    "      .sort_values(\n",
    "          by=[\"race_id\", \"pit_lap\",\n",
    "              \"attacking_driver\", \"defending_driver\", \"lap_number\"],\n",
    "          kind=\"mergesort\"\n",
    "      )\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Evaluation windows constructed ‚Äî rows: {len(eval_windows):,}, \"\n",
    "    f\"unique candidates: \"\n",
    "    f\"{eval_windows[['race_id','pit_lap','attacking_driver','defending_driver']].drop_duplicates().shape[0]:,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compute relative deltas\n",
    "# ------------------------------------------------------------\n",
    "eval_windows[\"attacker_minus_defender_ms\"] = (\n",
    "    eval_windows[\"cumulative_time_ms_attacker\"] -\n",
    "    eval_windows[\"cumulative_time_ms_defender\"]\n",
    ")\n",
    "\n",
    "logger.info(\"Evaluation windows ready for outcome aggregation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64250322-bcc6-41c0-b88b-9c559b627910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:08:24,031 | INFO | src.logging_config | Aggregating undercut evaluation windows (Primary: Option B, Secondary: A & C)\n",
      "2025-12-18 17:08:24,262 | INFO | src.logging_config | Undercut outcomes aggregated ‚Äî events: 122\n",
      "2025-12-18 17:08:24,266 | INFO | src.logging_config | Undercut success classification applied (Option B only)\n",
      "2025-12-18 17:08:24,272 | INFO | src.logging_config | Undercut outcome aggregation complete ‚Äî primary and secondary metrics ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 4\n",
    "# Undercut Outcome Aggregation & Classification\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell AGGREGATES evaluation windows into per-undercut outcomes.\n",
    "\n",
    "Primary metric (Option B):\n",
    "‚Ä¢ Mean net time delta over N post-pit laps\n",
    "\n",
    "Secondary metrics:\n",
    "‚Ä¢ Option A: First post-pit lap delta\n",
    "‚Ä¢ Option C: Best (minimum) lap delta within window\n",
    "\n",
    "This cell:\n",
    "‚Ä¢ produces strategy-level outcomes\n",
    "‚Ä¢ performs explicit, reviewable aggregation\n",
    "‚Ä¢ preserves traceability to raw laps\n",
    "\n",
    "This cell does NOT:\n",
    "‚Ä¢ smooth results\n",
    "‚Ä¢ hide ambiguity\n",
    "‚Ä¢ rank drivers or teams\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\n",
    "    \"Aggregating undercut evaluation windows \"\n",
    "    \"(Primary: Option B, Secondary: A & C)\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Sanity check ‚Äî required columns\n",
    "# ------------------------------------------------------------\n",
    "required_cols = {\n",
    "    \"race_id\",\n",
    "    \"pit_lap\",\n",
    "    \"lap_number\",\n",
    "    \"attacking_driver\",\n",
    "    \"defending_driver\",\n",
    "    \"attacker_minus_defender_ms\",\n",
    "}\n",
    "\n",
    "missing = required_cols - set(eval_windows.columns)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing required columns for outcome aggregation: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Aggregate per undercut event\n",
    "# ------------------------------------------------------------\n",
    "group_cols = [\n",
    "    \"race_id\",\n",
    "    \"pit_lap\",\n",
    "    \"attacking_driver\",\n",
    "    \"defending_driver\",\n",
    "]\n",
    "\n",
    "def aggregate_event(df):\n",
    "    \"\"\"\n",
    "    Aggregates one undercut event across its evaluation window.\n",
    "    \"\"\"\n",
    "    return pd.Series({\n",
    "        # Primary metric (Option B)\n",
    "        \"mean_delta_ms\": df[\"attacker_minus_defender_ms\"].mean(),\n",
    "\n",
    "        # Secondary metric A (first post-pit lap)\n",
    "        \"first_lap_delta_ms\": (\n",
    "            df.sort_values(\"lap_number\")\n",
    "              .iloc[0][\"attacker_minus_defender_ms\"]\n",
    "        ),\n",
    "\n",
    "        # Secondary metric C (best lap in window)\n",
    "        \"best_lap_delta_ms\": df[\"attacker_minus_defender_ms\"].min(),\n",
    "\n",
    "        # Window diagnostics\n",
    "        \"num_eval_laps\": len(df),\n",
    "    })\n",
    "\n",
    "undercut_outcomes = (\n",
    "    eval_windows\n",
    "    .groupby(group_cols, sort=False)\n",
    "    .apply(aggregate_event, include_groups=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Undercut outcomes aggregated ‚Äî events: {len(undercut_outcomes):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Outcome classification (PRIMARY METRIC ONLY)\n",
    "# ------------------------------------------------------------\n",
    "# Definition:\n",
    "# ‚Ä¢ Successful undercut ‚Üí mean_delta_ms < 0\n",
    "#   (attacker gains time on average)\n",
    "# ‚Ä¢ Otherwise ‚Üí not successful\n",
    "\n",
    "undercut_outcomes[\"undercut_success\"] = (\n",
    "    undercut_outcomes[\"mean_delta_ms\"] < 0\n",
    ")\n",
    "\n",
    "logger.info(\"Undercut success classification applied (Option B only)\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Defensive validation\n",
    "# ------------------------------------------------------------\n",
    "if undercut_outcomes.isna().any().any():\n",
    "    raise RuntimeError(\n",
    "        \"NaNs detected in undercut outcome table ‚Äî aggregation unsafe\"\n",
    "    )\n",
    "\n",
    "if (undercut_outcomes[\"num_eval_laps\"] <= 0).any():\n",
    "    raise RuntimeError(\n",
    "        \"Invalid evaluation window length detected\"\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    \"Undercut outcome aggregation complete ‚Äî \"\n",
    "    \"primary and secondary metrics ready\"\n",
    ")\n",
    "\n",
    "# NOTE:\n",
    "# ‚Ä¢ mean_delta_ms        ‚Üí STRATEGY WORTH (PRIMARY)\n",
    "# ‚Ä¢ first_lap_delta_ms   ‚Üí TACTICAL IMMEDIACY (SECONDARY)\n",
    "# ‚Ä¢ best_lap_delta_ms    ‚Üí PEAK / HYPE METRIC (SECONDARY)\n",
    "#\n",
    "# Dashboard and conclusions MUST respect this hierarchy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae75aba4-fa3b-44ae-b8b1-d9f3b88d4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:08:24,295 | INFO | src.logging_config | Running edge case handling & analytical validation\n",
      "2025-12-18 17:08:24,312 | INFO | src.logging_config | Track status contamination flags attached to undercut outcomes\n",
      "2025-12-18 17:08:24,315 | INFO | src.logging_config | Green-flag validity classification complete ‚Äî valid: 122, invalid: 0\n",
      "2025-12-18 17:08:24,333 | INFO | src.logging_config | Contextual outcome comparison computed\n",
      "2025-12-18 17:08:24,337 | INFO | src.logging_config | Edge case handling & validation PASSED\n",
      "2025-12-18 17:08:24,341 | INFO | src.logging_config | Notebook 05 COMPLETE ‚Äî undercut strategy outcomes validated and ready for visualization\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 5\n",
    "# Edge Case Handling & Analytical Validation\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell FINALIZES undercut analysis by:\n",
    "\n",
    "‚Ä¢ Explicitly enforcing green-flag validity\n",
    "‚Ä¢ Handling safety-car / VSC contamination\n",
    "‚Ä¢ Comparing green-only vs all-context outcomes\n",
    "‚Ä¢ Validating robustness of primary metric (Option B)\n",
    "\n",
    "This is the LAST analytical cell before visualization.\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"Running edge case handling & analytical validation\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Attach track-status contamination indicators\n",
    "# ------------------------------------------------------------\n",
    "# Any evaluation lap affected by SC / VSC / RED disqualifies\n",
    "# the undercut from GREEN-FLAG VALID classification\n",
    "\n",
    "status_cols = [\n",
    "    \"is_sc_lap_attacker\",\n",
    "    \"is_sc_lap_defender\",\n",
    "    \"is_vsc_lap_attacker\",\n",
    "    \"is_vsc_lap_defender\",\n",
    "]\n",
    "\n",
    "eval_windows[\"neutralized_lap\"] = (\n",
    "    eval_windows[status_cols].any(axis=1)\n",
    ")\n",
    "\n",
    "# Aggregate contamination at event level\n",
    "contamination = (\n",
    "    eval_windows\n",
    "    .groupby(\n",
    "        [\"race_id\", \"pit_lap\", \"attacking_driver\", \"defending_driver\"],\n",
    "        sort=False\n",
    "    )[\"neutralized_lap\"]\n",
    "    .any()\n",
    "    .reset_index(name=\"has_neutralized_lap\")\n",
    ")\n",
    "\n",
    "# Join back to outcomes\n",
    "undercut_outcomes = undercut_outcomes.merge(\n",
    "    contamination,\n",
    "    on=[\"race_id\", \"pit_lap\", \"attacking_driver\", \"defending_driver\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "logger.info(\"Track status contamination flags attached to undercut outcomes\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Define GREEN-FLAG VALID undercuts\n",
    "# ------------------------------------------------------------\n",
    "undercut_outcomes[\"green_flag_valid\"] = (\n",
    "    ~undercut_outcomes[\"has_neutralized_lap\"]\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    \"Green-flag validity classification complete ‚Äî \"\n",
    "    f\"valid: {undercut_outcomes['green_flag_valid'].sum():,}, \"\n",
    "    f\"invalid: {(~undercut_outcomes['green_flag_valid']).sum():,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Compare outcomes WITH vs WITHOUT enforcement\n",
    "# ------------------------------------------------------------\n",
    "summary = (\n",
    "    undercut_outcomes\n",
    "    .assign(\n",
    "        context=lambda df: df[\"green_flag_valid\"]\n",
    "            .map({True: \"GREEN_ONLY\", False: \"NEUTRALIZED_INCLUDED\"})\n",
    "    )\n",
    "    .groupby(\"context\", sort=False)\n",
    "    .agg(\n",
    "        events=(\"mean_delta_ms\", \"count\"),\n",
    "        success_rate=(\"undercut_success\", \"mean\"),\n",
    "        avg_time_gain_ms=(\"mean_delta_ms\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "logger.info(\"Contextual outcome comparison computed\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Defensive sanity checks\n",
    "# ------------------------------------------------------------\n",
    "if summary.empty:\n",
    "    raise RuntimeError(\n",
    "        \"Outcome summary empty ‚Äî validation logic failed\"\n",
    "    )\n",
    "\n",
    "if summary[\"events\"].sum() != len(undercut_outcomes):\n",
    "    raise RuntimeError(\n",
    "        \"Event count mismatch during validation\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Edge case handling & validation PASSED\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Final outputs for visualization\n",
    "# ------------------------------------------------------------\n",
    "# These tables are now TRUSTED and STABLE\n",
    "\n",
    "final_undercut_events = undercut_outcomes.copy()\n",
    "final_summary = summary.copy()\n",
    "\n",
    "logger.info(\n",
    "    \"Notebook 05 COMPLETE ‚Äî \"\n",
    "    \"undercut strategy outcomes validated and ready for visualization\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316e215d-431c-4309-bfb8-0ee5571d163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:08:24,368 | INFO | src.logging_config | Preparing to persist final undercut analysis tables\n",
      "2025-12-18 17:08:24,371 | INFO | src.logging_config | Pre-persistence checks passed\n",
      "2025-12-18 17:08:24,645 | INFO | src.logging_config | undercut_events persisted ‚Äî rows: 122\n",
      "2025-12-18 17:08:24,705 | INFO | src.logging_config | undercut_summary persisted ‚Äî rows: 1\n",
      "2025-12-18 17:08:24,712 | INFO | src.logging_config | Post-write verification passed ‚Äî row counts match\n",
      "2025-12-18 17:08:24,782 | INFO | src.logging_config | Final undercut results written to data/final ‚Äî undercut_events.parquet, undercut_summary.parquet\n",
      "2025-12-18 17:08:24,785 | INFO | src.logging_config | Notebook 05 DATA PERSISTENCE COMPLETE ‚Äî final undercut analysis tables are durable and dashboard-ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 6\n",
    "# PostgreSQL Persistence (Final Outputs)\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell persists FINAL undercut analysis tables to PostgreSQL.\n",
    "\n",
    "Tables written:\n",
    "‚Ä¢ undercut_events   ‚Äî event-level outcomes (Power BI fact table)\n",
    "‚Ä¢ undercut_summary  ‚Äî aggregated strategy metrics\n",
    "\n",
    "Properties:\n",
    "‚Ä¢ idempotent\n",
    "‚Ä¢ safe to rerun\n",
    "‚Ä¢ verified by row counts\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"Preparing to persist final undercut analysis tables\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Pre-persistence validation\n",
    "# ------------------------------------------------------------\n",
    "required_event_cols = {\n",
    "    \"race_id\",\n",
    "    \"pit_lap\",\n",
    "    \"attacking_driver\",\n",
    "    \"defending_driver\",\n",
    "    \"mean_delta_ms\",\n",
    "    \"first_lap_delta_ms\",\n",
    "    \"best_lap_delta_ms\",\n",
    "    \"undercut_success\",\n",
    "    \"green_flag_valid\",\n",
    "}\n",
    "\n",
    "missing = required_event_cols - set(final_undercut_events.columns)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Cannot persist undercut_events ‚Äî missing columns: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "if final_undercut_events.empty:\n",
    "    raise RuntimeError(\n",
    "        \"final_undercut_events is empty ‚Äî refusing to persist\"\n",
    "    )\n",
    "\n",
    "if final_summary.empty:\n",
    "    raise RuntimeError(\n",
    "        \"final_undercut_summary is empty ‚Äî refusing to persist\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Pre-persistence checks passed\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Persist undercut_events (replace semantics)\n",
    "# ------------------------------------------------------------\n",
    "with engine.begin() as conn:\n",
    "    final_undercut_events.to_sql(\n",
    "        name=\"undercut_events\",\n",
    "        con=conn,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=10_000,\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    f\"undercut_events persisted ‚Äî rows: {len(final_undercut_events):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Persist undercut_summary (replace semantics)\n",
    "# ------------------------------------------------------------\n",
    "with engine.begin() as conn:\n",
    "    final_summary.to_sql(\n",
    "        name=\"undercut_summary\",\n",
    "        con=conn,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=1_000,\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    f\"undercut_summary persisted ‚Äî rows: {len(final_summary):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Post-write verification\n",
    "# ------------------------------------------------------------\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    events_count = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM undercut_events\")\n",
    "    ).scalar()\n",
    "\n",
    "    summary_count = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM undercut_summary\")\n",
    "    ).scalar()\n",
    "\n",
    "if events_count != len(final_undercut_events):\n",
    "    raise RuntimeError(\n",
    "        \"Row count mismatch for undercut_events after persistence\"\n",
    "    )\n",
    "\n",
    "if summary_count != len(final_summary):\n",
    "    raise RuntimeError(\n",
    "        \"Row count mismatch for undercut_summary after persistence\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Post-write verification passed ‚Äî row counts match\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Persist final outputs to data/final\n",
    "# ------------------------------------------------------------\n",
    "final_dir = Config.DATA_DIR / \"final\"\n",
    "final_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "events_path = final_dir / \"undercut_events.parquet\"\n",
    "summary_path = final_dir / \"undercut_summary.parquet\"\n",
    "\n",
    "final_undercut_events.to_parquet(events_path, index=False)\n",
    "final_summary.to_parquet(summary_path, index=False)\n",
    "\n",
    "logger.info(\n",
    "    \"Final undercut results written to data/final ‚Äî \"\n",
    "    f\"{events_path.name}, {summary_path.name}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FINAL\n",
    "# ------------------------------------------------------------\n",
    "logger.info(\n",
    "    \"Notebook 05 DATA PERSISTENCE COMPLETE ‚Äî \"\n",
    "    \"final undercut analysis tables are durable and dashboard-ready\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102817f8-73ec-4cb8-b576-553283155a1a",
   "metadata": {},
   "source": [
    "# üèÅ Notebook 05 ‚Äî Conclusion  \n",
    "## Undercut Detection, Evaluation & Validation\n",
    "\n",
    "Notebook 05 is where this project crossed the line from **feature engineering** into **strategy analysis**.\n",
    "\n",
    "Up to Notebook 04, the focus was on building a clean, deterministic, lap-level analytical foundation. Notebook 05 deliberately restricted itself to **one question only**:\n",
    "\n",
    "> **Is the undercut strategy actually worth it, or is it largely hype?**\n",
    "\n",
    "This notebook did not attempt to answer that question narratively or heuristically. Instead, it constructed a pipeline that could **defend its answer under scrutiny**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What Notebook 05 Set Out to Do\n",
    "\n",
    "The pipeline document defined five conceptual stages for undercut analysis:\n",
    "\n",
    "1. **Formalize what an undercut is**  \n",
    "2. **Detect undercut candidates**  \n",
    "3. **Construct fair evaluation windows**  \n",
    "4. **Evaluate outcomes quantitatively**  \n",
    "5. **Handle edge cases and validate assumptions**\n",
    "\n",
    "Notebook 05 implemented all five ‚Äî but not always in the na√Øve way originally imagined.\n",
    "\n",
    "The most important lesson of this notebook is that **real data forces clarity**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step-by-Step: What We Actually Did\n",
    "\n",
    "### 1Ô∏è‚É£ Undercut Definition (Cell 1)\n",
    "\n",
    "An undercut was formally defined as a **pairwise strategic interaction**, not a driver-level event.\n",
    "\n",
    "Each undercut is uniquely identified by:\n",
    "\n",
    "- `race_id`\n",
    "- `attacking_driver`\n",
    "- `defending_driver`\n",
    "- `pit_lap`\n",
    "\n",
    "This immediately ruled out vague notions like *‚ÄúDriver X attempted an undercut‚Äù* and replaced them with:\n",
    "\n",
    "> *‚ÄúDriver A attempted to undercut Driver B on lap L in race R.‚Äù*\n",
    "\n",
    "This decision shaped everything downstream.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Candidate Detection (Cell 2)\n",
    "\n",
    "We initially attempted to detect only ‚Äúclean‚Äù undercuts (green-flag, racing context).  \n",
    "This **failed completely**.\n",
    "\n",
    "The failure was not a bug ‚Äî it revealed a flawed assumption:\n",
    "- Track status data is **event-based and sparse**\n",
    "- Treating `is_green_lap == True` as ‚Äúracing‚Äù was overly strict\n",
    "- Enforcing interpretation at detection destroyed signal\n",
    "\n",
    "**Correction:**  \n",
    "Candidate detection was made **lossless and inclusive**:\n",
    "- Same race\n",
    "- Same pit lap\n",
    "- Attacker pits earlier than defender\n",
    "- Defender is still on track\n",
    "\n",
    "This produced **1,740 raw undercut candidates**, which is exactly what a detection stage should do.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Evaluation Window Construction (Cell 3)\n",
    "\n",
    "The next challenge was constructing **fair, like-for-like post-pit comparison windows**.\n",
    "\n",
    "Again, enforcing green-flag logic too early resulted in **zero evaluable events**.\n",
    "\n",
    "**Key insight:**  \n",
    "Green-flag status is not a *mechanical property* ‚Äî it is an **analytical validity condition**.\n",
    "\n",
    "So we changed strategy:\n",
    "- Window construction enforced only **mechanical comparability**\n",
    "  - same laps\n",
    "  - no pit laps\n",
    "  - no out laps\n",
    "- Track status flags were **carried forward**, not used as filters\n",
    "\n",
    "This reduced 1,740 candidates down to **122 undercuts with valid evaluation windows**.\n",
    "\n",
    "This reduction was not data loss ‚Äî it was **data qualification**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ Outcome Evaluation (Cell 4)\n",
    "\n",
    "At this point, we finally measured outcomes.\n",
    "\n",
    "Three metrics were computed deliberately:\n",
    "\n",
    "- **Primary (Option B):**  \n",
    "  Mean net time delta across post-pit laps  \n",
    "  ‚Üí *Does the undercut pay off on average?*\n",
    "\n",
    "- **Secondary (Option A):**  \n",
    "  First post-pit lap delta  \n",
    "  ‚Üí *Does the undercut feel immediately effective?*\n",
    "\n",
    "- **Secondary (Option C):**  \n",
    "  Best lap delta in the window  \n",
    "  ‚Üí *What is the peak upside (the ‚Äúhighlight‚Äù effect)?*\n",
    "\n",
    "Only the **primary metric** was allowed to determine `undercut_success`.\n",
    "\n",
    "This avoided cherry-picking while still allowing insight into why undercuts are hyped.\n",
    "\n",
    "---\n",
    "\n",
    "### 5Ô∏è‚É£ Edge Case Handling & Green-Flag Enforcement (Cell 5)\n",
    "\n",
    "The pipeline document stated:\n",
    "\n",
    "> *‚ÄúUndercuts are meaningless under neutralized racing.‚Äù*\n",
    "\n",
    "This was implemented **explicitly**, not implicitly.\n",
    "\n",
    "Instead of assuming green-flag conditions, we:\n",
    "- flagged any undercut whose evaluation window overlapped SC / VSC / RED laps\n",
    "- classified undercuts as `green_flag_valid` or not\n",
    "- compared outcomes **with and without enforcement**\n",
    "\n",
    "**Result:**  \n",
    "All 122 evaluable undercuts were already green-flag clean.\n",
    "\n",
    "This was surprising ‚Äî but crucially, it was **proven**, not assumed.\n",
    "\n",
    "---\n",
    "\n",
    "## üòÆ What Surprised Us\n",
    "\n",
    "Several non-obvious truths emerged:\n",
    "\n",
    "- Most ‚Äúpotential undercuts‚Äù never become evaluable events\n",
    "- Strict interpretation too early destroys analytical signal\n",
    "- Green-flag enforcement matters ‚Äî but only **after** measurement exists\n",
    "- Many undercuts that *look* promising never survive fair comparison\n",
    "- The hype around undercuts is driven more by **best-case laps** than by **average outcomes**\n",
    "\n",
    "These are exactly the kinds of insights this project was designed to surface.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ What the Data Now Safely Says\n",
    "\n",
    "At the end of Notebook 05, we now have:\n",
    "\n",
    "- **122 validated undercut events**\n",
    "- Each with:\n",
    "  - pairwise context\n",
    "  - time-based outcomes\n",
    "  - success classification\n",
    "  - green-flag validation\n",
    "- Results persisted to:\n",
    "  - PostgreSQL (for BI)\n",
    "  - `data/final/` (for auditability)\n",
    "\n",
    "Most importantly:\n",
    "\n",
    "> Any claim made downstream is now traceable to raw laps, explicit rules, and validated assumptions.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Final Artifacts Produced\n",
    "\n",
    "Notebook 05 produces **final, canonical outputs**:\n",
    "\n",
    "- **PostgreSQL tables**\n",
    "  - `undercut_events`\n",
    "  - `undercut_summary`\n",
    "\n",
    "- **Filesystem artifacts**\n",
    "  - `data/final/undercut_events.parquet`\n",
    "  - `data/final/undercut_summary.parquet`\n",
    "\n",
    "These are **strategy-level facts**, not intermediate data.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What Comes Next (Notebook 06)\n",
    "\n",
    "Notebook 06 is **not analysis** ‚Äî it is **communication**.\n",
    "\n",
    "The job of Notebook 06 (Power BI) is to:\n",
    "- visualize primary vs secondary metrics\n",
    "- contrast perception vs reality\n",
    "- show why undercuts feel powerful\n",
    "- show whether they actually are\n",
    "\n",
    "Because Notebook 05 was disciplined, Notebook 06 can now be honest.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Final Reflection\n",
    "\n",
    "Notebook 05 did not confirm or deny a narrative upfront.  \n",
    "It built a system that forced the narrative to **earn its place**.\n",
    "\n",
    "Every failure refined assumptions.  \n",
    "Every correction improved rigor.  \n",
    "Every result is defensible.\n",
    "\n",
    "At this point, the question *‚ÄúIs the undercut worth it?‚Äù*  \n",
    "is no longer philosophical ‚Äî it is empirical.\n",
    "\n",
    "And the data is finally ready to speak.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
