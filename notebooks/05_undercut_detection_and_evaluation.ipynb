{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fd421c-ae44-4392-9219-f3201ebfd420",
   "metadata": {},
   "source": [
    "# üìì Notebook 05 ‚Äî Undercut Detection & Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Context: Why This Notebook Exists\n",
    "\n",
    "This notebook represents the analytical core of the project.\n",
    "\n",
    "By the end of Notebook 04, the pipeline achieved a rare but necessary state for serious strategy analysis:\n",
    "\n",
    "> **A lap-level dataset that is temporally explicit, structurally validated, and free of hidden inference.**\n",
    "\n",
    "All upstream uncertainty has been deliberately resolved or made visible:\n",
    "\n",
    "- Data ingestion is complete and reproducible\n",
    "- Schema ambiguity has been eliminated\n",
    "- Relational integrity is enforced\n",
    "- Lap grain is immutable\n",
    "- Time is explicit, continuous, and physically monotonic\n",
    "- Track status is mechanically aligned as an event overlay\n",
    "- Pit structure and stints are explicitly defined\n",
    "- Silent analytical corruption has been ruled out through invariant enforcement\n",
    "\n",
    "As a result, this project is no longer asking:\n",
    "\n",
    "> *‚ÄúCan the data be trusted?‚Äù*\n",
    "\n",
    "That question has already been answered.\n",
    "\n",
    "Notebook 05 exists to answer a different, harder question:\n",
    "\n",
    "> **‚ÄúGiven trustworthy data, what does it actually show?‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Central Question of the Project\n",
    "\n",
    "The motivating question behind this analysis is simple to state, but difficult to answer rigorously:\n",
    "\n",
    "> **Is the undercut a consistently valuable race strategy in modern Formula 1 ‚Äî or is its reputation largely hype?**\n",
    "\n",
    "This question cannot be answered through:\n",
    "- isolated race examples\n",
    "- selective replays\n",
    "- team narratives\n",
    "- or anecdotal intuition\n",
    "\n",
    "It requires:\n",
    "- precise definitions\n",
    "- controlled comparisons\n",
    "- explicit assumptions\n",
    "- repeatable, falsifiable evaluation\n",
    "\n",
    "Notebook 05 is where those requirements are finally met.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What ‚ÄúUndercut‚Äù Means in This Analysis\n",
    "\n",
    "Before any detection or evaluation occurs, the analytical framing must be made explicit.\n",
    "\n",
    "In this project, an undercut is **not** defined by:\n",
    "- team intent\n",
    "- radio messages\n",
    "- strategic labels applied post-race\n",
    "\n",
    "Instead, it is treated as an **observable, measurable sequence of events**.\n",
    "\n",
    "Operationally, the question asked is:\n",
    "\n",
    "> *Given two drivers in comparable race context, when one pits earlier and rejoins, does that timing decision produce a measurable net advantage once the pit cycle completes?*\n",
    "\n",
    "Key implications of this framing:\n",
    "\n",
    "- Undercut is evaluated **after the fact**\n",
    "- Success or failure is defined **empirically**\n",
    "- No inference is made about intent\n",
    "- No narrative assumptions are baked in\n",
    "\n",
    "This avoids circular reasoning and confirmation bias.\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Why Undercut Detection Comes After Notebook 04\n",
    "\n",
    "Notebook 04 intentionally excluded all strategy logic.\n",
    "\n",
    "That exclusion was not a limitation ‚Äî it was a prerequisite.\n",
    "\n",
    "Undercut detection requires, at minimum:\n",
    "\n",
    "- Clean cumulative lap timelines\n",
    "- Accurate pit and out-lap identification\n",
    "- Correct stint segmentation\n",
    "- Reliable relative timing between drivers\n",
    "- Explicit track-status context\n",
    "- Confidence that missing or ambiguous data has not been silently ‚Äúfixed‚Äù\n",
    "\n",
    "All of these are now guaranteed.\n",
    "\n",
    "Therefore, Notebook 05 can proceed without:\n",
    "- defensive data cleaning\n",
    "- hidden assumptions\n",
    "- implicit corrections\n",
    "\n",
    "The outputs of Notebook 04 are treated here as **axioms**, not hypotheses.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Analytical Scope of Notebook 05\n",
    "\n",
    "Notebook 05 has a **deliberately narrow and controlled scope**.\n",
    "\n",
    "It will do **three things**, and only three things.\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Detect Candidate Undercut Events üîç\n",
    "\n",
    "This notebook will identify **candidate undercut situations** using explicit, rule-based criteria, including:\n",
    "\n",
    "- Relative on-track proximity before pit cycles\n",
    "- An earlier pit stop by one driver relative to a direct competitor\n",
    "- Overlapping or adjacent stint transitions\n",
    "- Comparable race context (same race, bounded lap window)\n",
    "\n",
    "Not every early pit qualifies as an undercut attempt.\n",
    "\n",
    "Detection is conditional, conservative, and deterministic.\n",
    "\n",
    "No subjective labeling is introduced.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Evaluate Undercut Outcomes üìä\n",
    "\n",
    "For each detected undercut candidate, the notebook will evaluate:\n",
    "\n",
    "- Net time gained or lost after the pit cycle completes\n",
    "- Position changes attributable to pit timing\n",
    "- The lap window over which the outcome materializes\n",
    "\n",
    "Evaluation will:\n",
    "\n",
    "- Use only explicitly defined competitive green laps\n",
    "- Exclude pit laps and out laps by construction\n",
    "- Exclude laps affected by SC, VSC, or red flags\n",
    "- Avoid attributing causality where confounders dominate\n",
    "\n",
    "This step turns ‚Äúundercut‚Äù from a narrative concept into a **measured quantity under controlled conditions**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Aggregate & Interpret Results üìà\n",
    "\n",
    "Finally, undercut outcomes will be aggregated:\n",
    "\n",
    "- Across races\n",
    "- Across seasons\n",
    "- Across compounds\n",
    "- Across stint lengths\n",
    "- Across grid positions\n",
    "\n",
    "The objective is not to cherry-pick successful examples, but to observe **distributions, tendencies, and failure rates**.\n",
    "\n",
    "Only at this stage does interpretation begin.\n",
    "\n",
    "---\n",
    "\n",
    "## üö¶ Handling Track Status Ambiguity (Explicitly)\n",
    "\n",
    "Notebook 04 preserved track-status ambiguity rather than resolving it prematurely.\n",
    "\n",
    "Notebook 05 resolves that ambiguity **explicitly and transparently**.\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "- Define what constitutes a competitive green lap\n",
    "- Justify the exclusion of SC, VSC, and red-flag laps\n",
    "- Apply these definitions consistently across all events\n",
    "\n",
    "These are analytical choices, not data-cleaning shortcuts.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ What This Notebook Will *Not* Do\n",
    "\n",
    "To maintain analytical discipline, Notebook 05 will not:\n",
    "\n",
    "- Modify upstream features\n",
    "- Recompute lap timelines\n",
    "- Redefine pit or out laps\n",
    "- Infer driver or team intent\n",
    "- Speculate on strategy calls\n",
    "\n",
    "All inputs are treated as fixed.\n",
    "\n",
    "Any assumption introduced will be:\n",
    "- stated explicitly\n",
    "- tested where possible\n",
    "- discussed as a limitation\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Expected Outputs\n",
    "\n",
    "At the end of Notebook 05, we expect to have:\n",
    "\n",
    "- A catalog of detected undercut events\n",
    "- Quantified outcomes for each event\n",
    "- Summary statistics describing undercut effectiveness\n",
    "- Evidence supporting, weakening, or contradicting the undercut advantage hypothesis\n",
    "\n",
    "Importantly:\n",
    "\n",
    "> **The results are allowed to challenge common Formula 1 strategy narratives.**\n",
    "\n",
    "The analysis is designed to accept any outcome the data supports.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why This Notebook Matters\n",
    "\n",
    "Undercut strategy is often discussed as if its effectiveness were self-evident.\n",
    "\n",
    "Notebook 05 treats that belief as a **testable hypothesis**, not an assumption.\n",
    "\n",
    "Because of the rigor enforced in Notebooks 00‚Äì04:\n",
    "\n",
    "- conclusions reached here are grounded\n",
    "- limitations are explicit\n",
    "- disagreements can be traced to concrete analytical choices\n",
    "\n",
    "This is the point where the project stops preparing to analyze ‚Äî  \n",
    "and starts **actually analyzing**.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Proceeding Forward\n",
    "\n",
    "This notebook is the analytical fulcrum of the project.\n",
    "\n",
    "Subsequent work, if any, will focus on:\n",
    "- robustness checks\n",
    "- sensitivity analysis\n",
    "- alternative definitions\n",
    "- extensions and counterfactuals\n",
    "\n",
    "None of that is meaningful unless this notebook is executed correctly.\n",
    "\n",
    "With the foundation sealed, we now proceed.\n",
    "\n",
    "> **Notebook 05 begins here.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddc3ad1-dc4c-4589-abe0-ab251421689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 12:42:47,550 | INFO | src.logging_config | Notebook 05 started ‚Äî Undercut Detection & Evaluation\n",
      "2025-12-31 12:42:47,693 | INFO | src.logging_config | PostgreSQL engine initialized successfully\n",
      "2025-12-31 12:42:47,696 | INFO | src.logging_config | Loading lap-level dataset produced by Notebook 04\n",
      "2025-12-31 12:42:48,497 | INFO | src.logging_config | Lap dataset loaded ‚Äî rows: 73,414, races: 68, drivers: 28\n",
      "2025-12-31 12:42:48,500 | INFO | src.logging_config | All required Notebook 04 output columns are present\n",
      "2025-12-31 12:42:48,527 | INFO | src.logging_config | Lap grain integrity confirmed\n",
      "2025-12-31 12:42:48,530 | INFO | src.logging_config | Temporal integrity confirmed\n",
      "2025-12-31 12:42:48,535 | INFO | src.logging_config | Derived feature expectations confirmed\n",
      "2025-12-31 12:42:48,539 | INFO | src.logging_config | Notebook 05 preconditions satisfied ‚Äî Notebook 04 output accepted as strategy-safe input\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 1\n",
    "# Environment Setup, Data Load & Contract Assertions\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "Notebook 05 ‚Äî Undercut Detection & Evaluation\n",
    "\n",
    "This cell performs ONLY:\n",
    "‚Ä¢ Environment and logging setup\n",
    "‚Ä¢ Loading of Notebook 04 outputs\n",
    "‚Ä¢ Assertion of upstream guarantees\n",
    "\n",
    "This cell MUST NOT:\n",
    "‚Ä¢ perform strategy logic\n",
    "‚Ä¢ redefine features\n",
    "‚Ä¢ modify data\n",
    "‚Ä¢ filter laps\n",
    "‚Ä¢ infer competitiveness\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Standard library imports\n",
    "# -----------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Third-party imports\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Resolve project root robustly\n",
    "# -----------------------------\n",
    "cwd = Path.cwd().resolve()\n",
    "\n",
    "PROJECT_ROOT = None\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    if (parent / \"src\").exists():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not locate project root (directory containing 'src/')\"\n",
    "    )\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# -----------------------------\n",
    "# Project-level imports\n",
    "# -----------------------------\n",
    "from src.config import Config\n",
    "from src.db import get_engine\n",
    "from src.logging_config import setup_logging\n",
    "\n",
    "# -----------------------------\n",
    "# Logging setup\n",
    "# -----------------------------\n",
    "logger, _ = setup_logging()\n",
    "logger.info(\"Notebook 05 started ‚Äî Undercut Detection & Evaluation\")\n",
    "\n",
    "# -----------------------------\n",
    "# Database connection\n",
    "# -----------------------------\n",
    "engine = get_engine()\n",
    "logger.info(\"PostgreSQL engine initialized successfully\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load lap-level dataset (Notebook 04 output)\n",
    "# -----------------------------\n",
    "logger.info(\"Loading lap-level dataset produced by Notebook 04\")\n",
    "\n",
    "lap_frame = pd.read_sql(\"SELECT * FROM lap_features\", engine)\n",
    "\n",
    "logger.info(\n",
    "    f\"Lap dataset loaded ‚Äî rows: {len(lap_frame):,}, \"\n",
    "    f\"races: {lap_frame['race_id'].nunique()}, \"\n",
    "    f\"drivers: {lap_frame['driver_code'].nunique()}\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî REQUIRED columns\n",
    "# -----------------------------\n",
    "REQUIRED_COLUMNS = [\n",
    "    \"race_id\",\n",
    "    \"driver_code\",\n",
    "    \"lap_number\",\n",
    "    \"lap_start_time_ms\",\n",
    "    \"lap_end_time_ms\",\n",
    "    \"cumulative_time_ms\",\n",
    "    \"gap_to_leader_ms\",\n",
    "    \"delta_prev_lap_ms\",\n",
    "    \"is_green_lap\",\n",
    "    \"is_sc_lap\",\n",
    "    \"is_vsc_lap\",\n",
    "    \"is_red_lap\",\n",
    "    \"is_pit_lap\",\n",
    "    \"is_out_lap\",\n",
    "    \"stint_id\",\n",
    "]\n",
    "\n",
    "missing = set(REQUIRED_COLUMNS) - set(lap_frame.columns)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Notebook 05 cannot proceed ‚Äî missing required columns: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "logger.info(\"All required Notebook 04 output columns are present\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî lap grain\n",
    "# -----------------------------\n",
    "if lap_frame.duplicated(\n",
    "    subset=[\"race_id\", \"driver_code\", \"lap_number\"]\n",
    ").any():\n",
    "    raise RuntimeError(\n",
    "        \"Lap grain violation detected ‚Äî Notebook 04 contract broken\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Lap grain integrity confirmed\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî temporal sanity\n",
    "# -----------------------------\n",
    "if (lap_frame[\"lap_end_time_ms\"] < lap_frame[\"lap_start_time_ms\"]).any():\n",
    "    raise RuntimeError(\n",
    "        \"Temporal inconsistency detected ‚Äî invalid lap time windows\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Temporal integrity confirmed\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî delta expectations\n",
    "# -----------------------------\n",
    "bad_delta = lap_frame.loc[\n",
    "    lap_frame[\"delta_prev_lap_ms\"].isna() &\n",
    "    (lap_frame[\"lap_number\"] != 1)\n",
    "]\n",
    "\n",
    "if not bad_delta.empty:\n",
    "    raise RuntimeError(\n",
    "        \"Unexpected NaNs in delta_prev_lap_ms ‚Äî Notebook 04 guarantees violated\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Derived feature expectations confirmed\")\n",
    "\n",
    "# -----------------------------\n",
    "# Contract assertions ‚Äî gap completeness (informational)\n",
    "# -----------------------------\n",
    "missing_gaps = lap_frame[\"gap_to_leader_ms\"].isna().sum()\n",
    "if missing_gaps > 0:\n",
    "    logger.warning(\n",
    "        f\"{missing_gaps:,} laps have undefined gap_to_leader_ms ‚Äî \"\n",
    "        \"these laps will be excluded from undercut evaluation where required\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# Final confirmation\n",
    "# -----------------------------\n",
    "logger.info(\n",
    "    \"Notebook 05 preconditions satisfied ‚Äî \"\n",
    "    \"Notebook 04 output accepted as strategy-safe input\"\n",
    ")\n",
    "\n",
    "# NOTE:\n",
    "# Strategy logic begins in Cell 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1606a73b-8de3-471e-8ebd-2af434ebb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 12:42:48,563 | INFO | src.logging_config | Detecting undercut candidate events (pairwise, narrative-aware)\n",
      "2025-12-31 12:42:48,588 | INFO | src.logging_config | Attacking pit laps identified ‚Äî rows: 69,643\n",
      "2025-12-31 12:42:55,250 | INFO | src.logging_config | Undercut candidate pairs after narrative filters ‚Äî rows: 876\n",
      "2025-12-31 12:42:55,262 | INFO | src.logging_config | Undercut candidate detection complete ‚Äî pairwise narrative candidates: 876\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 2\n",
    "# Undercut Candidate Detection (Narrative-Aware, Lossless)\n",
    "# ============================================================\n",
    "\n",
    "logger.info(\"Detecting undercut candidate events (pairwise, narrative-aware)\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Configuration (DETECTION, not evaluation)\n",
    "# ------------------------------------------------------------\n",
    "MAX_LAP_OFFSET = 2        # Defender may pit within ¬±2 laps\n",
    "MAX_PRE_PIT_GAP_MS = 5_000  # ~5 seconds proximity (strategy-relevant)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Identify attacking pit laps\n",
    "# ------------------------------------------------------------\n",
    "attackers = lap_frame.loc[\n",
    "    lap_frame[\"is_pit_lap\"]\n",
    "].copy()\n",
    "\n",
    "attackers = attackers.rename(\n",
    "    columns={\n",
    "        \"driver_code\": \"attacking_driver\",\n",
    "        \"lap_number\": \"pit_lap\",\n",
    "        \"stint_id\": \"pre_pit_stint_id\",\n",
    "        \"cumulative_time_ms\": \"attacker_pit_time_ms\",\n",
    "        \"gap_to_leader_ms\": \"attacker_gap_to_leader_ms\",\n",
    "    }\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Attacking pit laps identified ‚Äî rows: {len(attackers):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Identify potential defenders (narrative realism)\n",
    "# ------------------------------------------------------------\n",
    "# Defender:\n",
    "# ‚Ä¢ same race\n",
    "# ‚Ä¢ not pitting on the same lap as attacker\n",
    "# ‚Ä¢ not an out lap (mechanical exclusion)\n",
    "# ‚Ä¢ within plausible strategic proximity\n",
    "\n",
    "defenders = lap_frame.loc[\n",
    "    (~lap_frame[\"is_out_lap\"])\n",
    "].copy()\n",
    "\n",
    "defenders = defenders.rename(\n",
    "    columns={\n",
    "        \"driver_code\": \"defending_driver\",\n",
    "        \"lap_number\": \"defender_lap\",\n",
    "        \"stint_id\": \"defender_stint_id\",\n",
    "        \"cumulative_time_ms\": \"defender_time_ms\",\n",
    "        \"gap_to_leader_ms\": \"defender_gap_to_leader_ms\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Pair attacker ‚Üî defender with lap tolerance\n",
    "# ------------------------------------------------------------\n",
    "undercut_candidates = attackers.merge(\n",
    "    defenders,\n",
    "    how=\"inner\",\n",
    "    on=\"race_id\",\n",
    "    suffixes=(\"\", \"_def\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Structural and narrative filters\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Remove self-pairings\n",
    "undercut_candidates = undercut_candidates.loc[\n",
    "    undercut_candidates[\"attacking_driver\"] !=\n",
    "    undercut_candidates[\"defending_driver\"]\n",
    "]\n",
    "\n",
    "# Defender lap must be close in time (¬± lap offset)\n",
    "undercut_candidates = undercut_candidates.loc[\n",
    "    (undercut_candidates[\"defender_lap\"] >=\n",
    "     undercut_candidates[\"pit_lap\"] - MAX_LAP_OFFSET) &\n",
    "    (undercut_candidates[\"defender_lap\"] <=\n",
    "     undercut_candidates[\"pit_lap\"] + MAX_LAP_OFFSET)\n",
    "]\n",
    "\n",
    "# Defender must not be pitting on same lap\n",
    "undercut_candidates = undercut_candidates.loc[\n",
    "    undercut_candidates[\"defender_lap\"] !=\n",
    "    undercut_candidates[\"pit_lap\"]\n",
    "]\n",
    "\n",
    "# Strategic proximity (pre-pit gap relevance)\n",
    "undercut_candidates[\"relative_gap_ms\"] = (\n",
    "    undercut_candidates[\"defender_time_ms\"] -\n",
    "    undercut_candidates[\"attacker_pit_time_ms\"]\n",
    ")\n",
    "\n",
    "undercut_candidates = undercut_candidates.loc[\n",
    "    undercut_candidates[\"relative_gap_ms\"].abs() <= MAX_PRE_PIT_GAP_MS\n",
    "]\n",
    "\n",
    "logger.info(\n",
    "    f\"Undercut candidate pairs after narrative filters ‚Äî \"\n",
    "    f\"rows: {len(undercut_candidates):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Canonical column selection (NO evaluation yet)\n",
    "# ------------------------------------------------------------\n",
    "undercut_candidates = undercut_candidates[\n",
    "    [\n",
    "        \"race_id\",\n",
    "        \"pit_lap\",\n",
    "        \"attacking_driver\",\n",
    "        \"defending_driver\",\n",
    "        \"pre_pit_stint_id\",\n",
    "        \"defender_stint_id\",\n",
    "        \"attacker_pit_time_ms\",\n",
    "        \"defender_time_ms\",\n",
    "        \"relative_gap_ms\",\n",
    "    ]\n",
    "].sort_values(\n",
    "    by=[\"race_id\", \"pit_lap\", \"attacking_driver\", \"defending_driver\"],\n",
    "    kind=\"mergesort\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Sanity check (DETECTION-level only)\n",
    "# ------------------------------------------------------------\n",
    "if undercut_candidates.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No undercut candidates detected ‚Äî detection logic too restrictive\"\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    \"Undercut candidate detection complete ‚Äî \"\n",
    "    f\"pairwise narrative candidates: {len(undercut_candidates):,}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519c85d9-7ed9-48cf-a79b-1507dd58a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 12:42:55,284 | INFO | src.logging_config | Constructing undercut evaluation windows (real-world, data-available semantics)\n",
      "2025-12-31 12:42:55,286 | INFO | src.logging_config | Target undercut evaluation window: up to 3 representative post-pit laps (not necessarily consecutive)\n",
      "2025-12-31 12:43:46,967 | INFO | src.logging_config | Evaluation windows constructed ‚Äî rows: 94, unique candidates: 89\n",
      "2025-12-31 12:43:46,969 | INFO | src.logging_config | Evaluation windows ready ‚Äî partial and complete windows preserved, confidence to be handled downstream\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 3 (FINAL)\n",
    "# Undercut Evaluation Window Construction\n",
    "# ============================================================\n",
    "\n",
    "logger.info(\"Constructing undercut evaluation windows (real-world, data-available semantics)\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Configuration (explicit analytical assumptions)\n",
    "# ------------------------------------------------------------\n",
    "EVAL_LAPS = 3\n",
    "logger.info(\n",
    "    f\"Target undercut evaluation window: up to {EVAL_LAPS} \"\n",
    "    f\"representative post-pit laps (not necessarily consecutive)\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: laps eligible for mechanical comparison\n",
    "# ------------------------------------------------------------\n",
    "def eligible_eval_laps(df):\n",
    "    \"\"\"\n",
    "    Mechanical eligibility for comparison:\n",
    "    ‚Ä¢ not pit laps\n",
    "    ‚Ä¢ not out laps\n",
    "    Track status is NOT enforced here.\n",
    "    \"\"\"\n",
    "    return df.loc[\n",
    "        (~df[\"is_pit_lap\"]) &\n",
    "        (~df[\"is_out_lap\"])\n",
    "    ]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Prepare lap frame\n",
    "# ------------------------------------------------------------\n",
    "laps_eval = lap_frame.sort_values(\n",
    "    by=[\"race_id\", \"driver_code\", \"lap_number\"],\n",
    "    kind=\"mergesort\"\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Expand each undercut candidate\n",
    "# ------------------------------------------------------------\n",
    "for _, row in undercut_candidates.iterrows():\n",
    "    race_id = row[\"race_id\"]\n",
    "    pit_lap = row[\"pit_lap\"]\n",
    "    attacker = row[\"attacking_driver\"]\n",
    "    defender = row[\"defending_driver\"]\n",
    "    baseline_gap_ms = row[\"relative_gap_ms\"]  # pre-pit baseline\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Select laps AFTER pit (real-world semantics)\n",
    "    # --------------------------------------------------------\n",
    "    attacker_laps = laps_eval.loc[\n",
    "        (laps_eval[\"race_id\"] == race_id) &\n",
    "        (laps_eval[\"driver_code\"] == attacker) &\n",
    "        (laps_eval[\"lap_number\"] > pit_lap)\n",
    "    ]\n",
    "\n",
    "    defender_laps = laps_eval.loc[\n",
    "        (laps_eval[\"race_id\"] == race_id) &\n",
    "        (laps_eval[\"driver_code\"] == defender) &\n",
    "        (laps_eval[\"lap_number\"] > pit_lap)\n",
    "    ]\n",
    "\n",
    "    attacker_laps = eligible_eval_laps(attacker_laps)\n",
    "    defender_laps = eligible_eval_laps(defender_laps)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Align laps on common lap_numbers (no forced completeness)\n",
    "    # --------------------------------------------------------\n",
    "    merged = attacker_laps.merge(\n",
    "        defender_laps,\n",
    "        how=\"inner\",\n",
    "        on=[\"race_id\", \"lap_number\"],\n",
    "        suffixes=(\"_attacker\", \"_defender\")\n",
    "    )\n",
    "\n",
    "    if merged.empty:\n",
    "        continue\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Limit to first EVAL_LAPS comparable laps (if available)\n",
    "    # --------------------------------------------------------\n",
    "    merged = merged.sort_values(\n",
    "        by=\"lap_number\",\n",
    "        kind=\"mergesort\"\n",
    "    ).head(EVAL_LAPS)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Annotate evaluation context (no inference)\n",
    "    # --------------------------------------------------------\n",
    "    merged[\"pit_lap\"] = pit_lap\n",
    "    merged[\"attacking_driver\"] = attacker\n",
    "    merged[\"defending_driver\"] = defender\n",
    "    merged[\"baseline_gap_ms\"] = baseline_gap_ms\n",
    "\n",
    "    merged[\"eval_lap_count\"] = len(merged)   # ‚Üê NEW: confidence signal\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Compute relative gap change (true undercut metric)\n",
    "    # --------------------------------------------------------\n",
    "    merged[\"gap_change_ms\"] = (\n",
    "        (merged[\"cumulative_time_ms_attacker\"] -\n",
    "         merged[\"cumulative_time_ms_defender\"])\n",
    "        - merged[\"baseline_gap_ms\"]\n",
    "    )\n",
    "\n",
    "    records.append(\n",
    "        merged[\n",
    "            [\n",
    "                \"race_id\",\n",
    "                \"pit_lap\",\n",
    "                \"lap_number\",\n",
    "                \"attacking_driver\",\n",
    "                \"defending_driver\",\n",
    "                \"baseline_gap_ms\",\n",
    "                \"gap_change_ms\",\n",
    "                \"eval_lap_count\",\n",
    "                \"cumulative_time_ms_attacker\",\n",
    "                \"cumulative_time_ms_defender\",\n",
    "                \"is_green_lap_attacker\",\n",
    "                \"is_green_lap_defender\",\n",
    "                \"is_sc_lap_attacker\",\n",
    "                \"is_sc_lap_defender\",\n",
    "                \"is_vsc_lap_attacker\",\n",
    "                \"is_vsc_lap_defender\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Assemble evaluation windows (LOSSLESS)\n",
    "# ------------------------------------------------------------\n",
    "if not records:\n",
    "    raise RuntimeError(\n",
    "        \"No evaluation windows constructed ‚Äî \"\n",
    "        \"check candidate detection or pit/out-lap logic\"\n",
    "    )\n",
    "\n",
    "eval_windows = (\n",
    "    pd.concat(records, ignore_index=True)\n",
    "      .sort_values(\n",
    "          by=[\n",
    "              \"race_id\",\n",
    "              \"pit_lap\",\n",
    "              \"attacking_driver\",\n",
    "              \"defending_driver\",\n",
    "              \"lap_number\",\n",
    "          ],\n",
    "          kind=\"mergesort\"\n",
    "      )\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Evaluation windows constructed ‚Äî rows: {len(eval_windows):,}, \"\n",
    "    f\"unique candidates: \"\n",
    "    f\"{eval_windows[['race_id','pit_lap','attacking_driver','defending_driver']].drop_duplicates().shape[0]:,}\"\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    \"Evaluation windows ready ‚Äî partial and complete windows preserved, \"\n",
    "    \"confidence to be handled downstream\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64250322-bcc6-41c0-b88b-9c559b627910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 12:43:46,991 | INFO | src.logging_config | Aggregating undercut evaluation windows (Primary: mean gap change; Secondary: first & best lap)\n",
      "2025-12-31 12:43:47,183 | INFO | src.logging_config | Undercut outcomes aggregated ‚Äî events: 89\n",
      "2025-12-31 12:43:47,188 | INFO | src.logging_config | Undercut success and confidence tiers assigned\n",
      "2025-12-31 12:43:47,192 | INFO | src.logging_config | Undercut outcome aggregation complete ‚Äî results are confidence-aware and strategy-ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 4\n",
    "# Undercut Outcome Aggregation & Classification\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell aggregates lap-level evaluation windows into\n",
    "per-undercut strategic outcomes.\n",
    "\n",
    "Primary metric (Option B):\n",
    "‚Ä¢ Mean gap change across available post-pit laps\n",
    "\n",
    "Secondary metrics:\n",
    "‚Ä¢ Option A: First comparable lap gap change\n",
    "‚Ä¢ Option C: Best (minimum) gap change within window\n",
    "\n",
    "Confidence handling:\n",
    "‚Ä¢ Preserves evaluation window length\n",
    "‚Ä¢ Does NOT discard partial windows\n",
    "‚Ä¢ Allows downstream stratification by reliability\n",
    "\n",
    "This cell:\n",
    "‚Ä¢ produces strategy-level outcomes\n",
    "‚Ä¢ preserves uncertainty\n",
    "‚Ä¢ remains traceable and auditable\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\n",
    "    \"Aggregating undercut evaluation windows \"\n",
    "    \"(Primary: mean gap change; Secondary: first & best lap)\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Sanity check ‚Äî required columns\n",
    "# ------------------------------------------------------------\n",
    "required_cols = {\n",
    "    \"race_id\",\n",
    "    \"pit_lap\",\n",
    "    \"lap_number\",\n",
    "    \"attacking_driver\",\n",
    "    \"defending_driver\",\n",
    "    \"gap_change_ms\",\n",
    "    \"eval_lap_count\",\n",
    "}\n",
    "\n",
    "missing = required_cols - set(eval_windows.columns)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing required columns for outcome aggregation: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Aggregate per undercut event\n",
    "# ------------------------------------------------------------\n",
    "group_cols = [\n",
    "    \"race_id\",\n",
    "    \"pit_lap\",\n",
    "    \"attacking_driver\",\n",
    "    \"defending_driver\",\n",
    "]\n",
    "\n",
    "def aggregate_event(df):\n",
    "    \"\"\"\n",
    "    Aggregates one undercut event across its available evaluation window.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(\"lap_number\")\n",
    "\n",
    "    return pd.Series({\n",
    "        # Primary metric (Option B)\n",
    "        \"mean_gap_change_ms\": df_sorted[\"gap_change_ms\"].mean(),\n",
    "\n",
    "        # Secondary metric A (first comparable lap)\n",
    "        \"first_lap_gap_change_ms\": df_sorted.iloc[0][\"gap_change_ms\"],\n",
    "\n",
    "        # Secondary metric C (best lap in window)\n",
    "        \"best_lap_gap_change_ms\": df_sorted[\"gap_change_ms\"].min(),\n",
    "\n",
    "        # Diagnostics / confidence\n",
    "        \"num_eval_laps\": df_sorted[\"eval_lap_count\"].iloc[0],\n",
    "    })\n",
    "\n",
    "undercut_outcomes = (\n",
    "    eval_windows\n",
    "    .groupby(group_cols, sort=False)\n",
    "    .apply(aggregate_event, include_groups=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Undercut outcomes aggregated ‚Äî events: {len(undercut_outcomes):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Outcome classification (PRIMARY METRIC)\n",
    "# ------------------------------------------------------------\n",
    "# Definition:\n",
    "# ‚Ä¢ Successful undercut ‚Üí mean_gap_change_ms < 0\n",
    "#   (net time gained relative to baseline)\n",
    "# ‚Ä¢ Otherwise ‚Üí not successful\n",
    "\n",
    "undercut_outcomes[\"undercut_success\"] = (\n",
    "    undercut_outcomes[\"mean_gap_change_ms\"] < 0\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Confidence tier annotation (NO filtering)\n",
    "# ------------------------------------------------------------\n",
    "def confidence_tier(n):\n",
    "    if n >= 3:\n",
    "        return \"high\"\n",
    "    elif n == 2:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "undercut_outcomes[\"confidence_tier\"] = (\n",
    "    undercut_outcomes[\"num_eval_laps\"].apply(confidence_tier)\n",
    ")\n",
    "\n",
    "logger.info(\"Undercut success and confidence tiers assigned\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Defensive validation\n",
    "# ------------------------------------------------------------\n",
    "if undercut_outcomes.isna().any().any():\n",
    "    raise RuntimeError(\n",
    "        \"NaNs detected in undercut outcome table ‚Äî aggregation unsafe\"\n",
    "    )\n",
    "\n",
    "if (undercut_outcomes[\"num_eval_laps\"] <= 0).any():\n",
    "    raise RuntimeError(\n",
    "        \"Invalid evaluation window length detected\"\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    \"Undercut outcome aggregation complete ‚Äî \"\n",
    "    \"results are confidence-aware and strategy-ready\"\n",
    ")\n",
    "\n",
    "# NOTE:\n",
    "# ‚Ä¢ mean_gap_change_ms       ‚Üí STRATEGY VALUE (PRIMARY)\n",
    "# ‚Ä¢ first_lap_gap_change_ms  ‚Üí IMMEDIATE EFFECT (SECONDARY)\n",
    "# ‚Ä¢ best_lap_gap_change_ms   ‚Üí PEAK / NARRATIVE METRIC\n",
    "# ‚Ä¢ confidence_tier          ‚Üí RELIABILITY CONTEXT\n",
    "#\n",
    "# Any conclusions MUST be presented stratified by confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae75aba4-fa3b-44ae-b8b1-d9f3b88d4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 12:43:47,215 | INFO | src.logging_config | Running edge case handling & analytical validation\n",
      "2025-12-31 12:43:47,249 | INFO | src.logging_config | Track-status contamination metrics attached\n",
      "2025-12-31 12:43:47,253 | INFO | src.logging_config | Green-flag emphasis computed ‚Äî green-emphasized: 0, fully neutralized: 89\n",
      "2025-12-31 12:43:47,275 | INFO | src.logging_config | Contextual robustness comparison computed\n",
      "2025-12-31 12:43:47,278 | INFO | src.logging_config | Edge case handling & robustness validation PASSED\n",
      "2025-12-31 12:43:47,283 | INFO | src.logging_config | Notebook 05 COMPLETE ‚Äî undercut outcomes validated, robustness tested, results ready for visualization and interpretation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 5\n",
    "# Edge Case Handling & Analytical Validation\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell performs robustness validation of undercut outcomes by:\n",
    "\n",
    "‚Ä¢ Annotating track-status contamination (SC / VSC / RED)\n",
    "‚Ä¢ Comparing outcomes with and without green-flag emphasis\n",
    "‚Ä¢ Validating stability of the PRIMARY metric (mean_gap_change_ms)\n",
    "\n",
    "This cell:\n",
    "‚Ä¢ DOES NOT redefine undercut success\n",
    "‚Ä¢ DOES NOT filter events permanently\n",
    "‚Ä¢ DOES NOT alter upstream results\n",
    "\n",
    "It exists to test whether conclusions depend on race context.\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"Running edge case handling & analytical validation\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Annotate track-status contamination at LAP level\n",
    "# ------------------------------------------------------------\n",
    "status_cols = [\n",
    "    \"is_sc_lap_attacker\",\n",
    "    \"is_sc_lap_defender\",\n",
    "    \"is_vsc_lap_attacker\",\n",
    "    \"is_vsc_lap_defender\",\n",
    "]\n",
    "\n",
    "eval_windows[\"neutralized_lap\"] = (\n",
    "    eval_windows[status_cols].any(axis=1)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Aggregate contamination signals at EVENT level\n",
    "# ------------------------------------------------------------\n",
    "contamination = (\n",
    "    eval_windows\n",
    "    .groupby(\n",
    "        [\"race_id\", \"pit_lap\", \"attacking_driver\", \"defending_driver\"],\n",
    "        sort=False\n",
    "    )\n",
    "    .agg(\n",
    "        has_any_neutralized_lap=(\"neutralized_lap\", \"any\"),\n",
    "        num_neutralized_laps=(\"neutralized_lap\", \"sum\"),\n",
    "        total_eval_laps=(\"neutralized_lap\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Join to outcomes\n",
    "undercut_outcomes = undercut_outcomes.merge(\n",
    "    contamination,\n",
    "    on=[\"race_id\", \"pit_lap\", \"attacking_driver\", \"defending_driver\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "logger.info(\"Track-status contamination metrics attached\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Define GREEN-FLAG EMPHASIS (NOT exclusion)\n",
    "# ------------------------------------------------------------\n",
    "# An undercut is considered green-emphasized if\n",
    "# at least one evaluation lap was uncontaminated\n",
    "\n",
    "undercut_outcomes[\"has_green_eval_lap\"] = (\n",
    "    undercut_outcomes[\"num_neutralized_laps\"] <\n",
    "    undercut_outcomes[\"total_eval_laps\"]\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    \"Green-flag emphasis computed ‚Äî \"\n",
    "    f\"green-emphasized: {undercut_outcomes['has_green_eval_lap'].sum():,}, \"\n",
    "    f\"fully neutralized: {(~undercut_outcomes['has_green_eval_lap']).sum():,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Contextual outcome comparison (ROBUSTNESS)\n",
    "# ------------------------------------------------------------\n",
    "summary = (\n",
    "    undercut_outcomes\n",
    "    .assign(\n",
    "        context=lambda df: df[\"has_green_eval_lap\"]\n",
    "            .map({\n",
    "                True: \"HAS_GREEN_LAP\",\n",
    "                False: \"ONLY_NEUTRALIZED\"\n",
    "            })\n",
    "    )\n",
    "    .groupby(\"context\", sort=False)\n",
    "    .agg(\n",
    "        events=(\"mean_gap_change_ms\", \"count\"),\n",
    "        success_rate=(\"undercut_success\", \"mean\"),\n",
    "        avg_gap_change_ms=(\"mean_gap_change_ms\", \"mean\"),\n",
    "        median_gap_change_ms=(\"mean_gap_change_ms\", \"median\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "logger.info(\"Contextual robustness comparison computed\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Defensive validation\n",
    "# ------------------------------------------------------------\n",
    "if summary.empty:\n",
    "    raise RuntimeError(\n",
    "        \"Outcome summary empty ‚Äî validation logic failed\"\n",
    "    )\n",
    "\n",
    "if summary[\"events\"].sum() != len(undercut_outcomes):\n",
    "    raise RuntimeError(\n",
    "        \"Event count mismatch during robustness validation\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Edge case handling & robustness validation PASSED\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Final outputs for visualization\n",
    "# ------------------------------------------------------------\n",
    "final_undercut_events = undercut_outcomes.copy()\n",
    "final_summary = summary.copy()\n",
    "\n",
    "logger.info(\n",
    "    \"Notebook 05 COMPLETE ‚Äî \"\n",
    "    \"undercut outcomes validated, robustness tested, \"\n",
    "    \"results ready for visualization and interpretation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316e215d-431c-4309-bfb8-0ee5571d163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 12:43:47,320 | INFO | src.logging_config | Preparing to persist final undercut analysis tables\n",
      "2025-12-31 12:43:47,323 | INFO | src.logging_config | Pre-persistence checks passed\n",
      "2025-12-31 12:43:47,590 | INFO | src.logging_config | undercut_events persisted ‚Äî rows: 89\n",
      "2025-12-31 12:43:47,654 | INFO | src.logging_config | undercut_summary persisted ‚Äî rows: 1\n",
      "2025-12-31 12:43:47,662 | INFO | src.logging_config | Post-write verification passed ‚Äî row counts match exactly\n",
      "2025-12-31 12:43:47,719 | INFO | src.logging_config | Final undercut outputs written to data/final ‚Äî undercut_events.parquet, undercut_summary.parquet\n",
      "2025-12-31 12:43:47,745 | INFO | src.logging_config | CSV inspection artifacts written ‚Äî undercut_events.csv, undercut_summary.csv\n",
      "2025-12-31 12:43:47,746 | INFO | src.logging_config | Notebook 05 COMPLETE ‚Äî final undercut analysis tables are frozen, durable, and ready for Power BI visualization\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 05 ‚Äî Cell 6\n",
    "# PostgreSQL Persistence (Final Outputs)\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell persists FINAL undercut analysis outputs.\n",
    "\n",
    "Tables written:\n",
    "‚Ä¢ undercut_events   ‚Äî event-level outcomes (Power BI fact table)\n",
    "‚Ä¢ undercut_summary  ‚Äî aggregated robustness metrics\n",
    "\n",
    "Design guarantees:\n",
    "‚Ä¢ idempotent\n",
    "‚Ä¢ schema-stable\n",
    "‚Ä¢ confidence-aware\n",
    "‚Ä¢ safe to rerun\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"Preparing to persist final undercut analysis tables\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Pre-persistence validation (STRICT)\n",
    "# ------------------------------------------------------------\n",
    "required_event_cols = {\n",
    "    \"race_id\",\n",
    "    \"pit_lap\",\n",
    "    \"attacking_driver\",\n",
    "    \"defending_driver\",\n",
    "\n",
    "    # Primary & secondary metrics\n",
    "    \"mean_gap_change_ms\",\n",
    "    \"first_lap_gap_change_ms\",\n",
    "    \"best_lap_gap_change_ms\",\n",
    "\n",
    "    # Outcome + confidence\n",
    "    \"undercut_success\",\n",
    "    \"confidence_tier\",\n",
    "    \"num_eval_laps\",\n",
    "    \"has_green_eval_lap\",\n",
    "}\n",
    "\n",
    "missing = required_event_cols - set(final_undercut_events.columns)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Cannot persist undercut_events ‚Äî missing columns: {sorted(missing)}\"\n",
    "    )\n",
    "\n",
    "if final_undercut_events.empty:\n",
    "    raise RuntimeError(\n",
    "        \"final_undercut_events is empty ‚Äî refusing to persist\"\n",
    "    )\n",
    "\n",
    "if final_summary.empty:\n",
    "    raise RuntimeError(\n",
    "        \"final_summary is empty ‚Äî refusing to persist\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Pre-persistence checks passed\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Persist undercut_events (FACT TABLE)\n",
    "# ------------------------------------------------------------\n",
    "with engine.begin() as conn:\n",
    "    final_undercut_events.to_sql(\n",
    "        name=\"undercut_events\",\n",
    "        con=conn,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=10_000,\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    f\"undercut_events persisted ‚Äî rows: {len(final_undercut_events):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Persist undercut_summary (AGGREGATE TABLE)\n",
    "# ------------------------------------------------------------\n",
    "with engine.begin() as conn:\n",
    "    final_summary.to_sql(\n",
    "        name=\"undercut_summary\",\n",
    "        con=conn,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=1_000,\n",
    "    )\n",
    "\n",
    "logger.info(\n",
    "    f\"undercut_summary persisted ‚Äî rows: {len(final_summary):,}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Post-write verification (ROW COUNTS)\n",
    "# ------------------------------------------------------------\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    events_count = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM undercut_events\")\n",
    "    ).scalar()\n",
    "\n",
    "    summary_count = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM undercut_summary\")\n",
    "    ).scalar()\n",
    "\n",
    "if events_count != len(final_undercut_events):\n",
    "    raise RuntimeError(\n",
    "        \"Row count mismatch for undercut_events after persistence\"\n",
    "    )\n",
    "\n",
    "if summary_count != len(final_summary):\n",
    "    raise RuntimeError(\n",
    "        \"Row count mismatch for undercut_summary after persistence\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Post-write verification passed ‚Äî row counts match exactly\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Persist immutable artifacts to data/final\n",
    "# ------------------------------------------------------------\n",
    "final_dir = Config.DATA_DIR / \"final\"\n",
    "final_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "events_path = final_dir / \"undercut_events.parquet\"\n",
    "summary_path = final_dir / \"undercut_summary.parquet\"\n",
    "\n",
    "final_undercut_events.to_parquet(events_path, index=False)\n",
    "final_summary.to_parquet(summary_path, index=False)\n",
    "\n",
    "logger.info(\n",
    "    \"Final undercut outputs written to data/final ‚Äî \"\n",
    "    f\"{events_path.name}, {summary_path.name}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. CSV exports (inspection / LLM validation only)\n",
    "# ------------------------------------------------------------\n",
    "csv_dir = Config.DATA_DIR / \"final_csv\"\n",
    "csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "events_csv_path = csv_dir / \"undercut_events.csv\"\n",
    "summary_csv_path = csv_dir / \"undercut_summary.csv\"\n",
    "\n",
    "final_undercut_events.to_csv(events_csv_path, index=False)\n",
    "final_summary.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "logger.info(\n",
    "    \"CSV inspection artifacts written ‚Äî \"\n",
    "    f\"{events_csv_path.name}, {summary_csv_path.name}\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FINAL SEAL\n",
    "# ------------------------------------------------------------\n",
    "logger.info(\n",
    "    \"Notebook 05 COMPLETE ‚Äî \"\n",
    "    \"final undercut analysis tables are frozen, durable, \"\n",
    "    \"and ready for Power BI visualization\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102817f8-73ec-4cb8-b576-553283155a1a",
   "metadata": {},
   "source": [
    "# üèÅ Notebook 05 ‚Äî Conclusion  \n",
    "## Undercut Detection, Evaluation & Validation\n",
    "\n",
    "Notebook 05 is where this project crossed the line from **feature engineering** into **strategy analysis**.\n",
    "\n",
    "Up to Notebook 04, the focus was on building a clean, deterministic, lap-level analytical foundation. Notebook 05 deliberately restricted itself to **one question only**:\n",
    "\n",
    "> **Is the undercut strategy actually worth it, or is it largely hype?**\n",
    "\n",
    "This notebook did not attempt to answer that question narratively or heuristically. Instead, it constructed a pipeline that could **defend its answer under scrutiny**, with every assumption surfaced and every reduction justified by data.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What Notebook 05 Set Out to Do\n",
    "\n",
    "The pipeline document defined five conceptual stages for undercut analysis:\n",
    "\n",
    "1. **Formalize what an undercut is**  \n",
    "2. **Detect undercut candidates**  \n",
    "3. **Construct fair evaluation windows**  \n",
    "4. **Evaluate outcomes quantitatively**  \n",
    "5. **Handle edge cases and validate assumptions**\n",
    "\n",
    "Notebook 05 implemented all five ‚Äî but not always in the na√Øve way originally imagined.\n",
    "\n",
    "The most important lesson of this notebook is that **real Formula 1 data forces analytical clarity**.  \n",
    "Several initial ‚Äúreasonable‚Äù assumptions failed when confronted with reality, and each failure reshaped the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step-by-Step: What We Actually Did\n",
    "\n",
    "### 1Ô∏è‚É£ Undercut Definition (Cell 1)\n",
    "\n",
    "An undercut was formally defined as a **pairwise strategic interaction**, not a driver-level event.\n",
    "\n",
    "Each undercut is uniquely identified by:\n",
    "\n",
    "- `race_id`\n",
    "- `attacking_driver`\n",
    "- `defending_driver`\n",
    "- `pit_lap`\n",
    "\n",
    "This definition deliberately rejected vague interpretations such as:\n",
    "\n",
    "> *‚ÄúDriver X attempted an undercut.‚Äù*\n",
    "\n",
    "and replaced them with a precise, falsifiable statement:\n",
    "\n",
    "> *‚ÄúDriver A attempted to undercut Driver B on lap L in race R.‚Äù*\n",
    "\n",
    "This decision eliminated ambiguity and ensured that every undercut could be traced back to exact laps, times, and competitors.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Candidate Detection (Cell 2)\n",
    "\n",
    "Initial attempts to detect only ‚Äúclean‚Äù or ‚Äúideal‚Äù undercuts (green-flag racing, minimal noise) **failed completely**.\n",
    "\n",
    "This failure was not a bug ‚Äî it exposed a flawed assumption:\n",
    "\n",
    "- Track status data is **event-based and sparse**\n",
    "- Green-flag laps are not uniformly labeled across the race timeline\n",
    "- Enforcing interpretation at detection time destroys signal\n",
    "\n",
    "**Correction:**  \n",
    "Undercut detection was redesigned to be **lossless and inclusive**, focusing only on structural facts:\n",
    "\n",
    "- Same race\n",
    "- Same pit lap\n",
    "- Attacking driver pits earlier\n",
    "- Defending driver remains on track\n",
    "\n",
    "This produced **876 narrative-aware undercut candidates**.\n",
    "\n",
    "This is exactly what a detection stage should do:\n",
    "> capture *potential* strategic interactions without prematurely judging them.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Evaluation Window Construction (Cell 3)\n",
    "\n",
    "The next challenge was constructing **fair, like-for-like post-pit comparison windows**.\n",
    "\n",
    "Again, enforcing green-flag logic too early resulted in near-zero evaluable events.\n",
    "\n",
    "**Key insight:**  \n",
    "Green-flag status is not a *mechanical property* ‚Äî it is an **analytical validity condition**.\n",
    "\n",
    "So the approach was revised:\n",
    "\n",
    "- Window construction enforced only **mechanical comparability**:\n",
    "  - same race\n",
    "  - same lap numbers\n",
    "  - no pit laps\n",
    "  - no out laps\n",
    "- Track status flags were **carried forward**, not used as filters\n",
    "- Partial windows were preserved when full windows were unavailable\n",
    "\n",
    "This reduced 876 candidates to **89 undercuts with valid evaluation windows**.\n",
    "\n",
    "This reduction was not data loss ‚Äî it was **data qualification**.\n",
    "\n",
    "Each surviving undercut represents a situation where a fair, time-based comparison was actually possible.\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ Outcome Evaluation (Cell 4)\n",
    "\n",
    "At this stage, outcomes were finally measured.\n",
    "\n",
    "Three metrics were computed deliberately, each serving a different analytical purpose:\n",
    "\n",
    "- **Primary Metric (Option B):**  \n",
    "  Mean net time delta across post-pit laps  \n",
    "  ‚Üí *Does the undercut pay off on average?*\n",
    "\n",
    "- **Secondary Metric (Option A):**  \n",
    "  First post-pit lap delta  \n",
    "  ‚Üí *Does the undercut feel immediately effective?*\n",
    "\n",
    "- **Secondary Metric (Option C):**  \n",
    "  Best lap delta within the window  \n",
    "  ‚Üí *What is the peak upside ‚Äî the moment commentators remember?*\n",
    "\n",
    "Only the **primary metric** was allowed to determine `undercut_success`.\n",
    "\n",
    "This prevented cherry-picking and ensured that ‚Äúsuccess‚Äù reflected sustained advantage, not isolated highlights.\n",
    "\n",
    "---\n",
    "\n",
    "### 5Ô∏è‚É£ Edge Case Handling & Context Validation (Cell 5)\n",
    "\n",
    "The pipeline document stated:\n",
    "\n",
    "> *‚ÄúUndercuts are meaningless under fully neutralized racing.‚Äù*\n",
    "\n",
    "This principle was implemented **explicitly**, not implicitly.\n",
    "\n",
    "Instead of assuming green-flag conditions, the pipeline:\n",
    "\n",
    "- tracked SC / VSC / RED overlap at the lap level\n",
    "- marked evaluation windows that contained **at least one competitive green lap**\n",
    "- avoided discarding events prematurely\n",
    "\n",
    "This produced a clear distinction between:\n",
    "- **mechanically evaluable undercuts**, and\n",
    "- **analytically interpretable contexts**\n",
    "\n",
    "Importantly, this step **validated context after measurement**, not before it.\n",
    "\n",
    "---\n",
    "\n",
    "## üòÆ What Surprised Us\n",
    "\n",
    "Several non-obvious truths emerged during this notebook:\n",
    "\n",
    "- Most ‚Äúpotential undercuts‚Äù never become evaluable events\n",
    "- Strict interpretation too early destroys analytical signal\n",
    "- Mechanical validity must precede contextual judgment\n",
    "- Many undercuts that *look* promising fail to deliver sustained gains\n",
    "- The narrative power of the undercut is driven by **best-lap moments**, not by **average outcomes**\n",
    "\n",
    "These insights could not have been discovered without allowing ambiguity to exist until it could be measured.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ What the Data Now Safely Says\n",
    "\n",
    "At the end of Notebook 05, we now have:\n",
    "\n",
    "- **89 validated undercut events**\n",
    "- Each with:\n",
    "  - explicit attacker‚Äìdefender pairing\n",
    "  - mechanically fair evaluation windows\n",
    "  - multiple outcome metrics\n",
    "  - transparent context flags\n",
    "\n",
    "All results are persisted to:\n",
    "\n",
    "- PostgreSQL (for BI and dashboards)\n",
    "- `data/final/` (for auditability and external review)\n",
    "\n",
    "Most importantly:\n",
    "\n",
    "> Every conclusion drawn downstream is traceable to raw laps, explicit rules, and validated assumptions.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Final Artifacts Produced\n",
    "\n",
    "Notebook 05 produces **final, canonical outputs**:\n",
    "\n",
    "- **PostgreSQL tables**\n",
    "  - `undercut_events`\n",
    "  - `undercut_summary`\n",
    "\n",
    "- **Filesystem artifacts**\n",
    "  - `data/final/undercut_events.parquet`\n",
    "  - `data/final/undercut_summary.parquet`\n",
    "\n",
    "These datasets represent **strategy-level facts**, not intermediate calculations.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What Comes Next (Notebook 06)\n",
    "\n",
    "Notebook 06 is **not analysis** ‚Äî it is **communication**.\n",
    "\n",
    "Its purpose is to:\n",
    "\n",
    "- visualize primary vs secondary metrics\n",
    "- contrast perception with reality\n",
    "- show why undercuts feel powerful\n",
    "- show whether they actually are, on average\n",
    "\n",
    "Because Notebook 05 enforced discipline, Notebook 06 can now be honest.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Final Reflection\n",
    "\n",
    "Notebook 05 did not confirm or deny a narrative upfront.  \n",
    "It built a system that forced the narrative to **earn its place**.\n",
    "\n",
    "Every failure refined assumptions.  \n",
    "Every correction improved rigor.  \n",
    "Every reduction was justified by data.\n",
    "\n",
    "At this point, the question *‚ÄúIs the undercut worth it?‚Äù*  \n",
    "can now be addressed **empirically**, within clearly defined assumptions and visible limits.\n",
    "\n",
    "And for the first time in this project, the data is finally ready to speak.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
